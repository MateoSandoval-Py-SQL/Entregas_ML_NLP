{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0F200N-wqO3"
   },
   "source": [
    "![image info](https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w75FGynzwqO3"
   },
   "source": [
    "# Proyecto 1 - Predicción de popularidad en canción\n",
    "\n",
    "En este proyecto podrán poner en práctica sus conocimientos sobre modelos predictivos basados en árboles y ensambles, y sobre la disponibilización de modelos. Para su desarrollo tengan en cuenta las instrucciones dadas en la \"Guía del proyecto 1: Predicción de popularidad en canción\".\n",
    "\n",
    "**Entrega**: La entrega del proyecto deberán realizarla durante la semana 4. Sin embargo, es importante que avancen en la semana 3 en el modelado del problema y en parte del informe, tal y como se les indicó en la guía.\n",
    "\n",
    "Para hacer la entrega, deberán adjuntar el informe autocontenido en PDF a la actividad de entrega del proyecto que encontrarán en la semana 4, y subir el archivo de predicciones a la [competencia de Kaggle](https://www.kaggle.com/competitions/miad-2025-12-prediccion-popularidad-en-cancion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiB84TdJwqO4"
   },
   "source": [
    "## Datos para la predicción de popularidad en cancion\n",
    "\n",
    "En este proyecto se usará el conjunto de datos de datos de popularidad en canciones, donde cada observación representa una canción y se tienen variables como: duración de la canción, acusticidad y tempo, entre otras. El objetivo es predecir qué tan popular es la canción. Para más detalles puede visitar el siguiente enlace: [datos](https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuzQAykBwqO4"
   },
   "source": [
    "## Ejemplo predicción conjunto de test para envío a Kaggle\n",
    "\n",
    "En esta sección encontrarán el formato en el que deben guardar los resultados de la predicción para que puedan subirlos a la competencia en Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1744039049283,
     "user": {
      "displayName": "Ana Maria Quintero",
      "userId": "04369708050989259997"
     },
     "user_tz": 300
    },
    "id": "5WHlajVlwqO4"
   },
   "outputs": [],
   "source": [
    "# Importación de Librerías\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1454,
     "status": "ok",
     "timestamp": 1744039599021,
     "user": {
      "displayName": "Ana Maria Quintero",
      "userId": "04369708050989259997"
     },
     "user_tz": 300
    },
    "id": "POuKslmYwqO5"
   },
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "dataTraining = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2025/main/datasets/dataTrain_Spotify.csv')\n",
    "dataTesting = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2025/main/datasets/dataTest_Spotify.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZm8t9NBwqO5"
   },
   "outputs": [],
   "source": [
    "# Visualización datos de entrenamiento\n",
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbrTQFErwqO5"
   },
   "outputs": [],
   "source": [
    "# Visualización datos de test\n",
    "dataTesting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Revisión inicial de los datos\n",
    "En esta sección se realiza una revisión inicial de los datos en la que se extrae la dimensión de los datos, se verifica la existencia de valores nulos, duplicados y el tipo de datos que hay en cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisión inicial de datos\n",
    "print(\"Dimensión de los datos de entrenamiento:\", dataTraining.shape)\n",
    "\n",
    "if dataTraining.isnull().sum().sum() > 0: # Verifica si hay valores nulos\n",
    "    print(\"\\nValores nulos en los datos de entrenamiento:\")\n",
    "    print(dataTraining.isnull().sum())\n",
    "else:\n",
    "    print(\"\\nNo hay valores nulos en los datos de entrenamiento.\")\n",
    "\n",
    "print(\"\\nNúmero de canciones duplicadas según Track_ID:\")\n",
    "print(dataTraining['track_id'].duplicated().sum())\n",
    "\n",
    "print(\"\\nTipos de variables en la base de datos:\")\n",
    "print(dataTraining.dtypes.unique())\n",
    "\n",
    "print(\"\\nVariables categóricas en la base de datos:\")\n",
    "print(dataTraining.select_dtypes(include=['object']).info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Limpieza de la base de datos\n",
    "En esta sección se realiza una depuración de los valores duplicados indentificados en el punto anterior, se depuran algunas variables que no serán incluidas en el modelo y se convierten a enteros las variables booleanas que fueron identificadas en la exploración inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de la base de datos\n",
    "data = dataTraining.drop_duplicates(subset='track_id', keep='first') # Eliminar duplicados\n",
    "data = data.drop(columns=['Unnamed: 0','track_id', 'artists', 'album_name', 'track_name', 'track_genre']) # Excluir columnas string\n",
    "\n",
    "columns_factorize = [col for col in data.columns if data[col].dtype == 'bool']\n",
    "for col in columns_factorize:\n",
    "    data[col] = pd.factorize(data[col])[0] # Convertir variables booleanas a enteros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Separación de datos de entrenamiento y prueba\n",
    "En esta sección se realiza la separación de los datos en entrenamiento y prueba según una partición de 67% - 33%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "X = data.drop(columns=['popularity']) # Variables predictoras\n",
    "y = data['popularity'] # Variable de interés\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Análisis descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de los datos de entrenamiento\n",
    "print(\"\\nEstadísticas descriptivas de los datos de entrenamiento:\")\n",
    "X_train.describe()\n",
    "print(\"\\nEstadísticas descriptivas de la variable de interés:\")\n",
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibración y Entrenamiento del Modelo Predictivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion y entrenamiento del modelo XGBRegressor\n",
    "XGBReg = XGBRegressor()\n",
    "\n",
    "# Entrenamiento (fit) y desempeño del modelo XGBRegressor\n",
    "XGBReg.fit(X_train, y_train)\n",
    "pred_XGBReg = XGBReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  15.4310\n",
      "RMSE:  19.3890\n",
      "R2:  0.1482\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "MAE_XGBReg = mean_absolute_error(y_test, pred_XGBReg)\n",
    "RMSE_XGBReg = np.sqrt(mean_squared_error(y_test, pred_XGBReg))\n",
    "R2_XGBReg = r2_score(y_test, pred_XGBReg)\n",
    "\n",
    "# Resultados\n",
    "print('MAE: ', f'{MAE_XGBReg:.4f}')\n",
    "print('RMSE: ', f'{RMSE_XGBReg:.4f}')\n",
    "print('R2: ', f'{R2_XGBReg:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación Predicción Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = XGBReg.predict(X_test)  # predicción sobre el conjunto de test\n",
    "# Convertir y_pred a DataFrame\n",
    "y_pred_df = pd.DataFrame(y_pred, index=dataTesting.index, columns=['Popularity'])\n",
    "# Guardar en CSV\n",
    "y_pred_df.to_csv('test_submission_xgbreg.csv', index_label='ID')\n",
    "y_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
