{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w75FGynzwqO3"
   },
   "source": [
    "# Informe Modelo Predictivo Popularidad de Canciones en Spotify\n",
    "<p style=\"text-align: justify;\">\n",
    "Este informe presenta el desarrollo de un modelo de aprendizaje automático, cuyo ibjetivo es predecir el nivel de popularidad de canciones en Spotify. A lo largo del documento se describen las etapas fundamentales del proceso, incluyendo el preprocesamiento de datos, la selección y calibración del modelo, el entrenamiento y evaluación del rendimiento, y la disponibilización del modelo mediante una API. El enfoque se basa en el uso de modelos de árboles de decisión y ensamblajes, implementados con Python.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#HOLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias a Importar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Modelado y evaluación\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Modelos base\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Preprocesamiento y selección de características\n",
    "import category_encoders as ce\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiB84TdJwqO4"
   },
   "source": [
    "## Preprocesamiento de Datos\n",
    "<p style=\"text-align: justify;\">\n",
    "En este proyecto se usaró el conjunto de datos de datos de popularidad en canciones, donde cada observación representa una canción y se tienen variables como: duración de la canción, acusticidad y tempo, entre otras. El objetivo es predecir qué tan popular es la canción.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2025/main/datasets/dataTrain_Spotify.csv')\n",
    "dataTesting = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2025/main/datasets/dataTest_Spotify.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+------------------------+-------------------+----------------------+----------------------------------------+---------------+------------+----------------+----------+-------+------------+--------+---------------+----------------+--------------------+------------+-----------+---------+------------------+---------------+--------------+\n",
      "|    |   Unnamed: 0 | track_id               | artists           | album_name           | track_name                             |   duration_ms | explicit   |   danceability |   energy |   key |   loudness |   mode |   speechiness |   acousticness |   instrumentalness |   liveness |   valence |   tempo |   time_signature | track_genre   |   popularity |\n",
      "|----+--------------+------------------------+-------------------+----------------------+----------------------------------------+---------------+------------+----------------+----------+-------+------------+--------+---------------+----------------+--------------------+------------+-----------+---------+------------------+---------------+--------------|\n",
      "|  0 |            0 | 7hUhmkALyQ8SX9mJs5XI3D | Love and Rockets  | Love and Rockets     | Motorcycle                             |        211533 | False      |          0.305 |   0.849  |     9 |    -10.795 |      1 |        0.0549 |       5.82e-05 |           0.0567   |     0.464  |    0.32   | 141.793 |                4 | goth          |           22 |\n",
      "|  1 |            1 | 5x59U89ZnjZXuNAAlc8X1u | Filippa Giordano  | Filippa Giordano     | Addio del passato - From \"La traviata\" |        196000 | False      |          0.287 |   0.19   |     7 |    -12.03  |      0 |        0.037  |       0.93     |           0.000356 |     0.0834 |    0.133  |  83.685 |                4 | opera         |           22 |\n",
      "|  2 |            2 | 70Vng5jLzoJLmeLu3ayBQq | Susumu Yokota     | Symbol               | Purple Rose Minuet                     |        216506 | False      |          0.583 |   0.509  |     1 |     -9.661 |      1 |        0.0362 |       0.777    |           0.202    |     0.115  |    0.544  |  90.459 |                3 | idm           |           37 |\n",
      "|  3 |            3 | 1cRfzLJapgtwJ61xszs37b | Franz Liszt;YUNDI | Relajación y siestas | Liebeslied (Widmung), S. 566           |        218346 | False      |          0.163 |   0.0368 |     8 |    -23.149 |      1 |        0.0472 |       0.991    |           0.899    |     0.107  |    0.0387 |  69.442 |                3 | classical     |            0 |\n",
      "|  4 |            4 | 47d5lYjbiMy0EdMRV8lRou | Scooter           | Scooter Forever      | The Darkside                           |        173160 | False      |          0.647 |   0.921  |     2 |     -7.294 |      1 |        0.185  |       0.000939 |           0.371    |     0.131  |    0.171  | 137.981 |                4 | techno        |           27 |\n",
      "+----+--------------+------------------------+-------------------+----------------------+----------------------------------------+---------------+------------+----------------+----------+-------+------------+--------+---------------+----------------+--------------------+------------+-----------+---------+------------------+---------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(dataTraining.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "A continuación, se valida la dimensión de los datos, los tipos de variables y se indentifica la existencia de valores faltantes y duplicados. Según los resultados, se identificaron valores duplicados y algunas variables string y categoricas. De igual forma se identifica que existen variables tipo <code>int64</code> y <code>float64</code>, los cuales podrían generan un uso importante de la memoria.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de los datos de entrenamiento: (79800, 21)\n",
      "\n",
      "No hay valores nulos en los datos de entrenamiento.\n",
      "\n",
      "Número de canciones duplicadas según Track_ID:\n",
      "13080\n",
      "\n",
      "Tipos de variables en la base de datos:\n",
      "[dtype('int64') dtype('O') dtype('bool') dtype('float64')]\n",
      "\n",
      "Variables string y categóricas en la base de datos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79800 entries, 0 to 79799\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   track_id     79800 non-null  object\n",
      " 1   artists      79800 non-null  object\n",
      " 2   album_name   79800 non-null  object\n",
      " 3   track_name   79800 non-null  object\n",
      " 4   explicit     79800 non-null  bool  \n",
      " 5   track_genre  79800 non-null  object\n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 3.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Revisión inicial de datos\n",
    "print(\"Dimensión de los datos de entrenamiento:\", dataTraining.shape)\n",
    "\n",
    "if dataTraining.isnull().sum().sum() > 0: # Verifica si hay valores nulos\n",
    "    print(\"\\nValores nulos en los datos de entrenamiento:\")\n",
    "    print(dataTraining.isnull().sum())\n",
    "else:\n",
    "    print(\"\\nNo hay valores nulos en los datos de entrenamiento.\")\n",
    "\n",
    "print(\"\\nNúmero de canciones duplicadas según Track_ID:\")\n",
    "print(dataTraining['track_id'].duplicated().sum())\n",
    "\n",
    "print(\"\\nTipos de variables en la base de datos:\")\n",
    "print(dataTraining.dtypes.unique())\n",
    "\n",
    "print(\"\\nVariables string y categóricas en la base de datos:\")\n",
    "print(dataTraining.select_dtypes(include=['object', 'bool']).info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "A continuación, se realizarán algunos ajustes a la base de datos. En primer lugar se optimiza el uso de memoria del dataset <code>dataTraining</code> ajustando los tipos de datos según su contenido. Este procedimiento es relevante porque reduce significativamente el consumo de memoria, mejorando la eficiencia del procesamiento y el rendimiento del modelo. Posteriormente, se eliminan las columnas que no se usarán, se transformarán las variables tipo <code>string</code> y <code>bool</code>.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de duplicados\n",
    "dataTraining = dataTraining.drop_duplicates(subset='track_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación tipológica de variables\n",
    "for col in dataTraining.columns:\n",
    "    col_type = dataTraining[col].dtype\n",
    "\n",
    "    if col_type == 'float64':\n",
    "        dataTraining[col] = dataTraining[col].astype('float32')\n",
    "    elif col_type == 'int64':\n",
    "        dataTraining[col] = dataTraining[col].astype('int32')\n",
    "    elif col_type == 'bool':\n",
    "        dataTraining[col] = dataTraining[col].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de variables nuevas\n",
    "# Se crean variables que pueden ser útiles para el modelo\n",
    "for df in [dataTraining, dataTesting]:\n",
    "    df['track_name_length'] = df['track_name'].apply(lambda x: len(str(x)))\n",
    "    df['tempo_density'] = df['tempo'] / df['duration_ms']\n",
    "    df['energy_danceability'] = df['energy'] * df['danceability']\n",
    "    df['acousticness_bin'] = (df['acousticness'] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de columnas innecesarias\n",
    "for col in ['Unnamed: 0']:\n",
    "    if col in dataTraining.columns: dataTraining.drop(columns=col, inplace=True)\n",
    "    if col in dataTesting.columns: dataTesting.drop(columns=col, inplace=True)\n",
    "\n",
    "drop_cols = ['track_id','artists','album_name','track_name', 'track_genre']\n",
    "X = dataTraining.drop(columns=drop_cols + ['popularity'])\n",
    "y = dataTraining['popularity']\n",
    "XTesting = dataTesting.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de variables usando Random Forest\n",
    "selector = SelectFromModel(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "selector.fit(X, y)\n",
    "X_sel = selector.transform(X)\n",
    "X_test_sel = selector.transform(XTesting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Estadísticas Descriptivas\n",
    "<p style=\"text-align: justify;\">\n",
    "En esta sección se realiza un análisis descriptivo de la base de datos. Se presentan las principales estadísticas descriptivas, así como histogramas, correlaciones y visualización de valores atípicos.<p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de entrenamiento\n",
    "dataTraining.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estilos de los gráficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Histograma de variables numéricas\n",
    "dataTraining.select_dtypes(include=np.number).hist(bins=30, figsize=(18, 12), color='skyblue', edgecolor='black')\n",
    "plt.suptitle(\"Distribución de variables numéricas\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mapa de calor de correlación\n",
    "plt.figure(figsize=(14, 10))\n",
    "corr = dataTraining.select_dtypes(include=np.number).corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title(\"Matriz de Correlación\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# --- 3. Boxplots para identificar outliers ---\n",
    "for col in dataTraining.select_dtypes(include=np.number).columns:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.boxplot(x=dataTraining[col], color='lightgreen')\n",
    "    plt.title(f\"Boxplot: {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables categóricas\n",
    "cat_cols = dataTraining.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "# Visualizar la cantidad de valores únicos por variable categórica\n",
    "print(\"Valores únicos por variable categórica:\")\n",
    "for col in cat_cols:\n",
    "    print(f\"{col}: {dataTraining[col].nunique()} valores únicos\")\n",
    "\n",
    "# Distribución de frecuencia de las principales categorías\n",
    "for col in cat_cols:\n",
    "    if dataTraining[col].nunique() <= 50:  # Limita el análisis a columnas con un número manejable de categorías\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        dataTraining[col].value_counts().head(20).plot(kind='bar', color='cornflowerblue')\n",
    "        plt.title(f\"Top 20 valores de {col}\")\n",
    "        plt.ylabel(\"Frecuencia\")\n",
    "        plt.xlabel(col)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "# Popularidad promedio por categoría\n",
    "for col in cat_cols:\n",
    "    if 'popularity' in dataTraining.columns and dataTraining[col].nunique() <= 50:\n",
    "        popularity_by_cat = dataTraining.groupby(col)['popularity'].mean().sort_values(ascending=False).head(20)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.barplot(x=popularity_by_cat.values, y=popularity_by_cat.index, palette=\"viridis\")\n",
    "        plt.title(f\"Popularidad promedio por {col} (Top 20)\")\n",
    "        plt.xlabel(\"Popularidad Promedio\")\n",
    "        plt.ylabel(col)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por 'track_genre' y calcular las medias de las columnas seleccionadas\n",
    "perfil_generos = dataTraining.groupby('track_genre')[dataTraining.select_dtypes(include=np.number).columns].mean().round(2).sort_values('popularity', ascending=False)\n",
    "\n",
    "# Mostrar el perfil\n",
    "print(perfil_generos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de Datos en Entrenamiento y Prueba\n",
    "<p style=\"text-align: justify;\">\n",
    "Se dividió el conjunto de datos en dos subconjuntos: uno de entrenamiento y otro de validación, utilizando una proporción del 80 % para entrenamiento y 20 % para validación.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección y Calibración del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los modelos base\n",
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=200, max_depth=30, random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=200, learning_rate=0.075, max_depth=5, random_state=42)),\n",
    "    ('xgb', XGBRegressor(n_estimators=200, learning_rate=0.075, max_depth=5, random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo de stacking\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=GradientBoostingRegressor(n_estimators=100, learning_rate=0.05, max_depth=3),\n",
    "    passthrough=True,\n",
    "    n_jobs=-1,\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar predicciones finales en el conjunto de prueba\n",
    "test_pred = stacking_model.predict(X_test_sel)\n",
    "submission = pd.DataFrame({'ID': dataTesting.index, 'popularity': test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el archivo de envío para Kaggle\n",
    "submission.to_csv('test_submission_file.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo de stacking con los datos transformados\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Realizar predicciones en el conjunto de validación\n",
    "y_pred = stacking_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {RMSE:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disponibilización del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
